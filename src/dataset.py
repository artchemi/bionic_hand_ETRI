import os
import sys
import json

import torch
from torch.utils.data import Dataset, WeightedRandomSampler

from scipy.io import loadmat
import numpy as np
import random

import utils
from tqdm import tqdm

from sklearn.preprocessing import OneHotEncoder
from sklearn.model_selection import train_test_split

sys.path.append(os.path.abspath(os.path.join(os.path.dirname(__file__), '..')))    # –ò–º–ø–æ—Ä—Ç–∏—Ä—É–µ–º –∫–æ—Ä–Ω–µ–≤—É—é –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é
from config import SUBJECTS, WINDOW_SIZE, GLOBAL_SEED, STEP_SIZE


def extract_emg_labels(subjects, exercise=2, window_size=WINDOW_SIZE, onehot=False) -> list:
    emgs = []
    labels = []

    for subject in tqdm(subjects): 
        file_path = f'data/s{subject}/S{subject}_E{exercise}_A1.mat'
        data = loadmat(file_path)

        emg_raw = data['emg'][:, 0:8] 
        labels_raw = data['stimulus']       

        emg_windows = utils.split_into_batches(emg_raw, window_size, STEP_SIZE)
        label_windows = utils.split_into_batches(labels_raw, window_size, STEP_SIZE)

        for emg_win, label_win in zip(emg_windows, label_windows):
            # üí• –î–æ–±–∞–≤–∏–º —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏—é –ø–æ —Ä–∞–∑–º–µ—Ä—É –æ–∫–Ω–∞ (–¥–æ–ª–∂–Ω–æ –±—ã—Ç—å —Ä–æ–≤–Ω–æ [window_size, 8])
            if emg_win.shape != (window_size, 8):
                continue

            labels_unique, freqs = np.unique(label_win, return_counts=True)

            if freqs.shape == (2,):
                idx_max = np.where(freqs == freqs.max())
                if len(idx_max[0]) == 2:
                    continue
                else:
                    emgs.append(emg_win)
                    labels.append(int(labels_unique[idx_max[0][0]]))
            else:
                emgs.append(emg_win)
                labels.append(int(labels_unique[0]))

    if onehot:
        enc = OneHotEncoder(sparse_output=False)
        labels = enc.fit_transform(np.array(labels).reshape(-1, 1))      

    return np.asarray(emgs), np.asarray(labels)


class EMGTransform:
    def __init__(self, normalize=True):
        self.normalize = normalize

    def __call__(self, x):
        if self.normalize:
            # –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è –ø–æ –∫–∞–Ω–∞–ª–∞–º (–æ—Å—å 0 ‚Äî –≤—Ä–µ–º–µ–Ω–Ω–∞—è, –æ—Å—å 1 ‚Äî –∫–∞–Ω–∞–ª—ã)
            x = (x - x.mean(dim=0)) / (x.std(dim=0) + 1e-6)
        return x
    

class SurfaceEMGDataset(Dataset):
    def __init__(self, emg: np.ndarray, labels:np.ndarray, gestures: list, transform=None):
        self.emg = emg
        self.labels = labels

        self.X = []
        self.y = []

        self.transform = transform

        # print(self.labels.shape)
        # print(type(self.emg))
        for gesture in gestures:
            idxs = np.where(self.labels == gesture)[0]

            # print(idxs)

            self.X.extend(self.emg[idxs])
            self.y.extend(self.labels[idxs])

    def __len__(self):
        return len(self.X)

    def __getitem__(self, idx):
        X = torch.tensor(self.X[idx], dtype=torch.float32)
        y = torch.tensor(self.y[idx], dtype=torch.long)    # NOTE: –î–ª—è BCE –Ω—É–∂–µ–Ω —Ç–∏–ø Long 

        if self.transform:
            X = self.transform(X)

        return X, y
    

def make_weighted_sampler(dataset):
    """
    –ü—Ä–∏–Ω–∏–º–∞–µ—Ç –¥–∞—Ç–∞—Å–µ—Ç, —É –∫–æ—Ç–æ—Ä–æ–≥–æ –≤ dataset.y –ª–µ–∂–∞—Ç –º–µ—Ç–∫–∏ (list –∏–ª–∏ np.ndarray),
    –∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç WeightedRandomSampler.
    """
    # –°–æ–±–∏—Ä–∞–µ–º –≤—Å–µ –º–µ—Ç–∫–∏
    labels = torch.tensor(dataset.y, dtype=torch.long)
    num_classes = int(labels.max().item()) + 1

    # –°—á–∏—Ç–∞–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø—Ä–∏–º–µ—Ä–æ–≤ –∫–∞–∂–¥–æ–≥–æ –∫–ª–∞—Å—Å–∞
    class_counts = torch.bincount(labels, minlength=num_classes).float()

    # –í–µ—Å–∞ –¥–ª—è –∫–∞–∂–¥–æ–≥–æ –∫–ª–∞—Å—Å–∞: total_samples / (num_classes * count_i)
    total_samples = len(labels)
    class_weights = total_samples / (num_classes * class_counts)
    # –í–µ—Å –∫–∞–∂–¥–æ–≥–æ –ø—Ä–∏–º–µ—Ä–∞ = –≤–µ—Å –µ–≥–æ –∫–ª–∞—Å—Å–∞
    sample_weights = class_weights[labels]

    sampler = WeightedRandomSampler(
        weights=sample_weights,
        num_samples=total_samples,
        replacement=True
    )
    return sampler

def compute_stats(emg_array):
    """
    –í—ã—á–∏—Å–ª–∏—Ç—å —Å—Ä–µ–¥–Ω–µ–µ –∏ œÉ –ø–æ –∫–∞–∂–¥–æ–º—É –∫–∞–Ω–∞–ª—É –¥–ª—è –≤—Å–µ–≥–æ –¥–∞—Ç–∞—Å–µ—Ç–∞.
    emg_array: np.ndarray –∏–ª–∏ torch.Tensor —Ñ–æ—Ä–º—ã [N, window, C]
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç:
        means: torch.Tensor —Ñ–æ—Ä–º—ã [C]
        stds:  torch.Tensor —Ñ–æ—Ä–º—ã [C]
    """
    # –ü—Ä–∏–≤–æ–¥–∏–º –∫ —Ç–µ–Ω–∑–æ—Ä—É
    if not isinstance(emg_array, torch.Tensor):
        emg = torch.tensor(emg_array, dtype=torch.float32)
    else:
        emg = emg_array.float()
    # –ü–µ—Ä–µ–º–µ—â–∞–µ–º –∫–∞–Ω–∞–ª—ã –Ω–∞ –≤—Ç–æ—Ä—É—é –æ—Å—å: [N, C, window]
    emg = emg.permute(0, 2, 1)
    means = emg.mean(dim=(0, 2))
    stds  = emg.std(dim=(0, 2))
    return means, stds

def save_stats(means, stds, path):
    """–°–æ—Ö—Ä–∞–Ω–∏—Ç—å means –∏ stds –≤ JSON."""
    stats = {'mean': means.tolist(), 'std': stds.tolist()}
    with open(path, 'w') as f:
        json.dump(stats, f)

def load_stats(path):
    """–ó–∞–≥—Ä—É–∑–∏—Ç—å means –∏ stds –∏–∑ JSON."""
    with open(path, 'r') as f:
        data = json.load(f)
    return torch.tensor(data['mean']), torch.tensor(data['std'])

class GlobalStandardizer:
    def __init__(self, means, stds):
        """
        means, stds: torch.Tensor —Ñ–æ—Ä–º—ã [C]
        """
        self.means = means
        self.stds  = stds
        
    def __call__(self, x):
        """
        x: torch.Tensor —Ñ–æ—Ä–º—ã [window, C] –∏–ª–∏ [C, window]
        –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç: torch.Tensor —Ñ–æ—Ä–º—ã [C, window]
        """
        if not isinstance(x, torch.Tensor):
            x = torch.tensor(x, dtype=torch.float32)
        
        # –ï—Å–ª–∏ –ø–µ—Ä–≤—ã–π —Ä–∞–∑–º–µ—Ä –Ω–µ —Ä–∞–≤–µ–Ω —á–∏—Å–ª—É –∫–∞–Ω–∞–ª–æ–≤, —Ç—Ä–∞–Ω—Å–ø–æ–Ω–∏—Ä—É–µ–º
        C = self.means.shape[0]
        if x.ndim == 2 and x.shape[0] != C:
            # –ø—Ä–µ–¥–ø–æ–ª–∞–≥–∞–µ–º, —á—Ç–æ x.shape == [window, C]
            x = x.permute(1, 0)
        
        # –¢–µ–ø–µ—Ä—å x: [C, window]
        return (x - self.means.unsqueeze(1)) / (self.stds.unsqueeze(1))
    

def gestures(emg: np.ndarray,
             labels: np.ndarray,
             targets: list = [0, 1, 3, 6],
             relax_shrink: int = 80000,
             rand_seed: int = 2022):
    """
    –ê–Ω–∞–ª–æ–≥ TensorFlow-—Ñ—É–Ω–∫—Ü–∏–∏ gestures(): 
      - –†–∞–∑–±–∏–≤–∞–µ—Ç —Å—ç–º–ø–ª—ã –ø–æ –∫–ª–∞—Å—Å–∞–º (targets).
      - –£—Ä–µ–∑–∞–µ—Ç –∫–ª–∞—Å—Å 0 –¥–æ relax_shrink.
      - –°–∫–ª–µ–∏–≤–∞–µ—Ç –æ–±—Ä–∞—Ç–Ω–æ —Å–ø–∏—Å–∫–∏ –≤ –¥–≤–∞ –º–∞—Å—Å–∏–≤–∞.
    
    Args:
        emg (np.ndarray): shape [N, window, C]
        labels (np.ndarray): shape [N]
        targets (list): —Å–ø–∏—Å–æ–∫ –º–µ—Ç–æ–∫, –∫–æ—Ç–æ—Ä—ã–µ –Ω–∞—Å –∏–Ω—Ç–µ—Ä–µ—Å—É—é—Ç
        relax_shrink (int): –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –æ–±—Ä–∞–∑—Ü–æ–≤ –∫–ª–∞—Å—Å–∞ 0, –∫–æ—Ç–æ—Ä–æ–µ –æ—Å—Ç–∞–≤–ª—è–µ–º
        rand_seed (int): —Å–∏–¥ –¥–ª—è reproducibility
    
    Returns:
        emg_out (np.ndarray): undersampled EMG, shape [M, window, C]
        labels_out (np.ndarray): –º–µ—Ç–∫–∏, shape [M]
    """
    # 1) –°–æ–±–∏—Ä–∞–µ–º –ø–æ –∫–ª–∞—Å—Å–∞–º
    class_dict = {t: [] for t in targets}
    for x, y in zip(emg, labels):
        if y in class_dict:
            class_dict[y].append(x)
    
    # 2) –£—Ä–µ–∑–∞–µ–º –∫–ª–∞—Å—Å 0 (relax), –µ—Å–ª–∏ —Ç—Ä–µ–±—É–µ—Ç—Å—è
    random.seed(rand_seed)
    if 0 in class_dict and relax_shrink is not None:
        relax_list = class_dict[0]
        if len(relax_list) > relax_shrink:
            class_dict[0] = random.sample(relax_list, relax_shrink)
        # –∏–Ω–∞—á–µ –æ—Å—Ç–∞–≤–ª—è–µ–º –≤—Å–µ
    
    # 3) –°–æ–±–∏—Ä–∞–µ–º –æ–±—Ä–∞—Ç–Ω–æ —Å–ø–∏—Å–∫–∏ –≤ –ø–ª–æ—Å–∫–∏–µ –º–∞—Å—Å–∏–≤—ã
    emg_out = []
    labels_out = []
    for label, samples in class_dict.items():
        emg_out.extend(samples)
        labels_out.extend([label] * len(samples))
    
    # 4) –ü–µ—Ä–µ–º–µ—à–∏–≤–∞–µ–º –æ–±—â–∏–π –ø–æ—Ä—è–¥–æ–∫
    combined = list(zip(emg_out, labels_out))
    random.seed(rand_seed)
    random.shuffle(combined)
    emg_out, labels_out = zip(*combined)
    
    return np.stack(emg_out), np.array(labels_out, dtype=np.int64)

    


def main():
    # means, stds = compute_stats(emg_train)      # emg_train: np.ndarray [N, window, C]
    # save_stats(means, stds, 'emg_stats.json')
    pass


if __name__ == "__main__":
    main()