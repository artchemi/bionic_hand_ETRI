import os
import sys

import torch
from torch.utils.data import Dataset

from scipy.io import loadmat
import numpy as np

import utils
from tqdm import tqdm

from sklearn.preprocessing import OneHotEncoder
from sklearn.model_selection import train_test_split

sys.path.append(os.path.abspath(os.path.join(os.path.dirname(__file__), '..')))    # –ò–º–ø–æ—Ä—Ç–∏—Ä—É–µ–º –∫–æ—Ä–Ω–µ–≤—É—é –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é
from config import SUBJECTS, WINDOW_SIZE, GLOBAL_SEED, STEP_SIZE


# def extract_emg_labels(subjects, exercise=2, window_size=WINDOW_SIZE) -> list:
#     emgs = []
#     labels = []

#     for subject in tqdm(subjects): 
#         file_path = f'data/s{subject}/S{subject}_E{exercise}_A1.mat'
#         data = loadmat(file_path)

#         # NOTE: –î–æ–±–∞–≤–ª—è—é—Ç—Å—è –ø–µ—Ä–≤—ã–µ 8 –∫–æ–ª–æ–Ω–æ–∫, –∫–æ—Ç–æ—Ä—ã–µ —Ä–∞–≤–Ω–æ–º–µ—Ä–Ω–æ —Ä–∞—Å–ø–æ–ª–æ–∂–µ–Ω—ã –≤–æ–∫—Ä—É–≥ 
#         # –ø—Ä–µ–¥–ø–ª–µ—á—å—è –Ω–∞ –≤—ã—Å–æ—Ç–µ –ª—É—á–µ–∑–∞–ø—è—Å—Ç–Ω–æ–≥–æ —Å—É—Å—Ç–∞–≤–∞
#         emg_raw = data['emg'][:,0:8] 
#         labels_raw = data['stimulus']       

#         emg_windows = utils.split_into_batches(emg_raw, window_size)
#         label_windows = utils.split_into_batches(labels_raw, window_size)

#         for emg_win, label_win in zip(emg_windows, label_windows):
#             labels_unique, freqs = np.unique(label_win, return_counts=True)

#             if freqs.shape == (2,):
#                 idx_max = np.where(freqs == freqs.max())
#                 if len(idx_max[0]) == 2:  # —Ä–∞–≤–Ω—ã–µ —á–∞—Å—Ç–æ—Ç—ã
#                     continue
#                 else:
#                     emgs.append(emg_win)
#                     labels.append(int(labels_unique[idx_max[0][0]]))
#             else:
#                 emgs.append(emg_win)
#                 labels.append(int(labels_unique[0]))

#     enc = OneHotEncoder(sparse_output=False)
#     labels_encoded = enc.fit_transform(np.array(labels).reshape(-1, 1))            
#     # TODO: –î–æ–±–∞–≤–∏—Ç—å one-hot –∫–æ–¥–∏—Ä–æ–≤–∞–Ω–∏–µ 
#     return emgs, labels_encoded

def extract_emg_labels(subjects, exercise=2, window_size=WINDOW_SIZE, onehot=True) -> list:
    emgs = []
    labels = []

    for subject in tqdm(subjects): 
        file_path = f'data/s{subject}/S{subject}_E{exercise}_A1.mat'
        data = loadmat(file_path)

        emg_raw = data['emg'][:, 0:8] 
        labels_raw = data['stimulus']       

        emg_windows = utils.split_into_batches(emg_raw, window_size, STEP_SIZE)
        label_windows = utils.split_into_batches(labels_raw, window_size, STEP_SIZE)

        for emg_win, label_win in zip(emg_windows, label_windows):
            # üí• –î–æ–±–∞–≤–∏–º —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏—é –ø–æ —Ä–∞–∑–º–µ—Ä—É –æ–∫–Ω–∞ (–¥–æ–ª–∂–Ω–æ –±—ã—Ç—å —Ä–æ–≤–Ω–æ [window_size, 8])
            if emg_win.shape != (window_size, 8):
                continue

            labels_unique, freqs = np.unique(label_win, return_counts=True)

            if freqs.shape == (2,):
                idx_max = np.where(freqs == freqs.max())
                if len(idx_max[0]) == 2:
                    continue
                else:
                    emgs.append(emg_win)
                    labels.append(int(labels_unique[idx_max[0][0]]))
            else:
                emgs.append(emg_win)
                labels.append(int(labels_unique[0]))

    if onehot:
        enc = OneHotEncoder(sparse_output=False)
        labels = enc.fit_transform(np.array(labels).reshape(-1, 1))      

    return np.asarray(emgs), np.asarray(labels)


class EMGTransform:
    def __init__(self, normalize=True):
        self.normalize = normalize

    def __call__(self, x):
        if self.normalize:
            # –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è –ø–æ –∫–∞–Ω–∞–ª–∞–º (–æ—Å—å 0 ‚Äî –≤—Ä–µ–º–µ–Ω–Ω–∞—è, –æ—Å—å 1 ‚Äî –∫–∞–Ω–∞–ª—ã)
            x = (x - x.mean(dim=0)) / (x.std(dim=0) + 1e-6)
        return x
    

class SurfaceEMGDataset(Dataset):
    def __init__(self, emg: np.ndarray, labels:np.ndarray, gestures: list, transform=None):
        self.emg = emg
        self.labels = labels

        self.X = []
        self.y = []

        self.transform = transform

        # print(self.labels.shape)
        # print(type(self.emg))
        for gesture in gestures:
            idxs = np.where(self.labels == gesture)[0]

            # print(idxs)

            self.X.extend(self.emg[idxs])
            self.y.extend(self.labels[idxs])


    def __len__(self):
        return len(self.emg)

    def __getitem__(self, idx):
        X = torch.tensor(self.X[idx], dtype=torch.float32)
        y = torch.tensor(self.y[idx], dtype=torch.float32)

        if self.transform:
            X = self.transform(X)

        return X, y
        

def main():
    # TODO: –ù–∞–ø–∏—Å–∞—Ç—å —Ç–µ—Å—Ç –¥–ª—è —ç—Ç–æ–≥–æ –¥–∞—Ç–∞—Å–µ—Ç–∞
    # emg, labels = extract_emg_labels(SUBJECTS, exercise=2, window_size=WINDOW_SIZE)
    # emg_train, emg_test, labels_train, labels_test = train_test_split(emg, labels, train_size=0.7, random_state=GLOBAL_SEED)

    # transform = EMGTransform(normalize=True)
    # train_dataset = SurfaceEMGDataset(emg=emg_train, labels_encoded=labels_train, transform=transform)
    # test_dataset = SurfaceEMGDataset(emg=emg_test, labels_encoded=labels_test, transform=transform)
    
    # print(len(train_dataset))
    # print(len(test_dataset))

    pass

if __name__ == "__main__":
    main()